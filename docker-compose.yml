services:
  otel-collector:
    image: otel/opentelemetry-collector-contrib:latest
    container_name: otel-collector
    command: ["--config=/etc/otel-collector-config.yaml"]
    volumes:
      - ./otel-collector-config.yaml:/etc/otel-collector-config.yaml:ro
    ports:
      - "4317:4317" # OTLP gRPC
      - "4318:4318" # OTLP HTTP
      - "8889:8889" # Prometheus metrics
    depends_on:
      - loki
    restart: unless-stopped
    # Note: distroless image — no curl/wget for in-container health checks.
    # Health is monitored via the Stack Health dashboard panels instead.

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./recording-rules.yml:/etc/prometheus/recording-rules.yml:ro
      - prometheus_data:/prometheus
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.path=/prometheus"
      - "--storage.tsdb.retention.time=90d"
      - "--web.enable-lifecycle"
    ports:
      - "9090:9090"
    depends_on:
      - otel-collector
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s

  renderer:
    image: grafana/grafana-image-renderer:latest
    container_name: grafana-renderer
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:?set in .env}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:?set in .env}
      - GF_USERS_ALLOW_SIGN_UP=false
      # External URL (must match the host-mapped port for image export)
      - GF_SERVER_ROOT_URL=http://localhost:3500/
      # Image renderer (remote rendering service)
      - GF_RENDERING_SERVER_URL=http://renderer:8081/render
      - GF_RENDERING_CALLBACK_URL=http://grafana:3000/
      # SMTP for alert email notifications
      - GF_SMTP_ENABLED=${GF_SMTP_ENABLED:-false}
      - GF_SMTP_HOST=${GF_SMTP_HOST:-}
      - GF_SMTP_USER=${GF_SMTP_USER:-}
      - GF_SMTP_PASSWORD=${GF_SMTP_PASSWORD:-}
      - GF_SMTP_FROM_ADDRESS=${GF_SMTP_FROM_ADDRESS:-alerts@claude-code-metrics.local}
      - GF_SMTP_FROM_NAME=${GF_SMTP_FROM_NAME:-Claude Code Metrics}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning:ro
      - ./grafana/dashboards:/var/lib/grafana/dashboards:ro
    ports:
      - "3500:3000"
    depends_on:
      prometheus:
        condition: service_healthy
      loki:
        condition: service_started
      renderer:
        condition: service_started
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "-q", "--spider", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 15s

  loki:
    image: grafana/loki:latest
    container_name: loki
    volumes:
      - loki_data:/loki
      - ./loki-config.yaml:/etc/loki/local-config.yaml:ro
    ports:
      - "3100:3100"
    command: -config.file=/etc/loki/local-config.yaml
    restart: unless-stopped
    # Note: distroless image — no shell or wget/curl for in-container health checks.
    # Health is monitored via the Stack Health dashboard panels instead.

  promtail:
    image: grafana/promtail:latest
    container_name: promtail
    volumes:
      - ./promtail-config.yaml:/etc/promtail/config.yaml:ro
      - ${HOME}/.claude/projects:/claude-projects:ro
      - promtail_data:/var/lib/promtail
    command: -config.file=/etc/promtail/config.yaml
    depends_on:
      - loki
    restart: unless-stopped
    # Note: distroless image — no shell or wget/curl for in-container health checks.

  transcript-server:
    build:
      context: ./scripts
      dockerfile: Dockerfile.transcripts
    container_name: transcript-server
    environment:
      - TRANSCRIPT_INTERVAL=120
    volumes:
      - ${HOME}/.claude/projects:/claude-projects:ro
      - transcript_data:/transcripts
      - sessions_data:/sessions-backup
    ports:
      - "8080:8080"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "python3 -c \"import urllib.request; urllib.request.urlopen('http://localhost:8080/')\""]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 20s

volumes:
  prometheus_data:
  grafana_data:
  loki_data:
  transcript_data:
  promtail_data:
  sessions_data:
